{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilialize_poplulation(numberOfParents):\n",
    "    learningRate = np.empty([numberOfParents, 1])\n",
    "    nEstimators = np.empty([numberOfParents, 1], dtype = np.uint8)\n",
    "    maxDepth = np.empty([numberOfParents, 1], dtype = np.uint8)\n",
    "    minChildWeight = np.empty([numberOfParents, 1])\n",
    "    gammaValue = np.empty([numberOfParents, 1])\n",
    "    subSample = np.empty([numberOfParents, 1])\n",
    "    colSampleByTree =  np.empty([numberOfParents, 1])\n",
    "    \n",
    "    for i in range(numberOfParents):\n",
    "            print(i)\n",
    "            learningRate[i] = round(random.uniform(0.01, 1), 2)\n",
    "            nEstimators[i] = random.randrange(10, 1500, step = 25)\n",
    "            maxDepth[i] = int(random.randrange(1, 10, step= 1))\n",
    "            minChildWeight[i] = round(random.uniform(0.01, 10.0), 2)\n",
    "            gammaValue[i] = round(random.uniform(0.01, 10.0), 2)\n",
    "            subSample[i] = round(random.uniform(0.01, 1.0), 2)\n",
    "            colSampleByTree[i] = round(random.uniform(0.01, 1.0), 2)\n",
    "    \n",
    "    population = np.concatenate((learningRate, nEstimators, maxDepth, minChildWeight, gammaValue, subSample, colSampleByTree), axis= 1)\n",
    "    return population\n",
    "\n",
    "\n",
    "def fitness_f1score(y_true, y_pred):\n",
    "    fitness = round((f1_score(y_true, y_pred, average='weighted')), 4)\n",
    "    return fitness\n",
    "\n",
    "\n",
    "#train the data annd find fitness score\n",
    "def train_population(population, dMatrixTrain, dMatrixtest, y_test,X,ys):\n",
    "    fScore = []\n",
    "    for i in range(population.shape[0]):\n",
    "        param = { 'objective':'binary:logistic',\n",
    "              'learning_rate': population[i][0],\n",
    "              'n_estimators': int(population[i][1]), \n",
    "              'max_depth': int(population[i][2]), \n",
    "              'min_child_weight': population[i][3],\n",
    "              'gamma': population[i][4], \n",
    "              'subsample': population[i][5],\n",
    "              'colsample_bytree': population[i][6],\n",
    "              'seed': 24}\n",
    "        num_round = 100\n",
    "        xgbT = xgb.train(param, dMatrixTrain, num_round)\n",
    "        xgbcv= xgb.XGBClassifier(random_state=1,learning_rate=0.01)\n",
    "        preds = xgbT.predict(dMatrixtest)\n",
    "        preds = preds>0.5\n",
    "        \n",
    "        classifier=xgb.XGBClassifier(learning_rate=  population[i][0] ,\n",
    "                    n_estimators= int(population[i][1]) ,\n",
    "                    max_depth=  int(population[i][2]) ,\n",
    "                    min_child_weight= population[i][3] ,\n",
    "                    gamma= population[i][4] ,\n",
    "                    subsample= population[i][5] ,\n",
    "                    colsample_bytree= population[i][6])\n",
    "        cvscore=cross_val_score(classifier,X,y,cv=10)\n",
    "        p=[]\n",
    "        for i in cvscore:\n",
    "            if math.isnan(i):\n",
    "                p=p\n",
    "            else:\n",
    "                p+=[i]\n",
    "        p=np.array(p)\n",
    "        p\n",
    "        fScore.append(sm/cnt)\n",
    "#         fScore.append(fitness_f1score(y_test, preds))\n",
    "    return fScore\n",
    "\n",
    "#select parents for mating\n",
    "def new_parents_selection(population, fitness, numParents):\n",
    "    selectedParents = np.empty((numParents, population.shape[1])) #create an array to store fittest parents\n",
    "    \n",
    "    #find the top best performing parents\n",
    "    for parentId in range(numParents):\n",
    "        bestFitnessId = np.where(fitness == np.max(fitness))\n",
    "        bestFitnessId  = bestFitnessId[0][0]\n",
    "        selectedParents[parentId, :] = population[bestFitnessId, :]\n",
    "        fitness[bestFitnessId] = -1 #set this value to negative, in case of F1-score, so this parent is not selected again\n",
    "    return selectedParents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Mate these parents to create children having parameters from these parents (we are using uniform crossover method)\n",
    "'''\n",
    "def crossover_uniform(parents, childrenSize):\n",
    "    \n",
    "    crossoverPointIndex = np.arange(0, np.uint8(childrenSize[1]), 1, dtype= np.uint8) #get all the index\n",
    "    crossoverPointIndex1 = np.random.randint(0, np.uint8(childrenSize[1]), np.uint8(childrenSize[1]/2)) # select half  of the indexes randomly\n",
    "    crossoverPointIndex2 = np.array(list(set(crossoverPointIndex) - set(crossoverPointIndex1))) #select leftover indexes\n",
    "    \n",
    "    children = np.empty(childrenSize)\n",
    "    \n",
    "    '''\n",
    "    Create child by choosing parameters from two parents selected using new_parent_selection function. The parameter values\n",
    "    will be picked from the indexes, which were randomly selected above. \n",
    "    '''\n",
    "    for i in range(childrenSize[0]):\n",
    "        \n",
    "        #find parent 1 index \n",
    "        parent1_index = i%parents.shape[0]\n",
    "        #find parent 2 index\n",
    "        parent2_index = (i+1)%parents.shape[0]\n",
    "        #insert parameters based on random selected indexes in parent 1\n",
    "        children[i, crossoverPointIndex1] = parents[parent1_index, crossoverPointIndex1]\n",
    "        #insert parameters based on random selected indexes in parent 1\n",
    "        children[i, crossoverPointIndex2] = parents[parent2_index, crossoverPointIndex2]\n",
    "    return children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(crossover, numberOfParameters):\n",
    "    #Define minimum and maximum values allowed for each parameter\n",
    "    minMaxValue = np.zeros((numberOfParameters, 2))\n",
    "    \n",
    "    minMaxValue[0:] = [0.01, 1.0] #min/max learning rate\n",
    "    minMaxValue[1, :] = [10, 2000] #min/max n_estimator\n",
    "    minMaxValue[2, :] = [1, 15] #min/max depth\n",
    "    minMaxValue[3, :] = [0, 10.0] #min/max child_weight\n",
    "    minMaxValue[4, :] = [0.01, 10.0] #min/max gamma\n",
    "    minMaxValue[5, :] = [0.01, 1.0] #min/maxsubsample\n",
    "    minMaxValue[6, :] = [0.01, 1.0] #min/maxcolsample_bytree\n",
    " \n",
    "    # Mutation changes a single gene in each offspring randomly.\n",
    "    mutationValue = 0\n",
    "    parameterSelect = np.random.randint(0, 7, 1)\n",
    "    print(parameterSelect)\n",
    "    if parameterSelect == 0: #learning_rate\n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "    if parameterSelect == 1: #n_estimators\n",
    "        mutationValue = np.random.randint(-200, 200, 1)\n",
    "    if parameterSelect == 2: #max_depth\n",
    "        mutationValue = np.random.randint(-5, 5, 1)\n",
    "    if parameterSelect == 3: #min_child_weight\n",
    "        mutationValue = round(np.random.uniform(5, 5), 2)\n",
    "    if parameterSelect == 4: #gamma\n",
    "        mutationValue = round(np.random.uniform(-2, 2), 2)\n",
    "    if parameterSelect == 5: #subsample\n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "    if parameterSelect == 6: #colsample\n",
    "        mutationValue = round(np.random.uniform(-0.5, 0.5), 2)\n",
    "  \n",
    "    #indtroduce mutation by changing one parameter, and set to max or min if it goes out of range\n",
    "    for idx in range(crossover.shape[0]):\n",
    "        crossover[idx, parameterSelect] = crossover[idx, parameterSelect] + mutationValue\n",
    "        if(crossover[idx, parameterSelect] > minMaxValue[parameterSelect, 1]):\n",
    "            crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 1]\n",
    "        if(crossover[idx, parameterSelect] < minMaxValue[parameterSelect, 0]):\n",
    "            crossover[idx, parameterSelect] = minMaxValue[parameterSelect, 0]    \n",
    "    return crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "np.random.seed(723)\n",
    "# Importing the dataset\n",
    "\n",
    "Train_Data = pd.read_csv('Encoded_Train_Data.csv')\n",
    "Val_Data = pd.read_csv('Encoded_Val_Data.csv') \n",
    "Test_Data = pd.read_csv('Encoded_Test_Data.csv') \n",
    "\n",
    "Continus = ['Age','Discount_Rate','Room_Rate','checkin_month','Adults', 'Children', 'Babies',\n",
    "            'Days_until_checkin','Booking_month','Min_num_of_rooms','Total_Min_Cost','Min_Discount_amount']\n",
    "\n",
    "Categorical = ['Gender','Educational_Level','Income','Meal_Type', 'Visted_Previously','Previous_Cancellations', 'Use_Promotion',\n",
    "              'Ethnicity_African American', 'Ethnicity_Asian American','Ethnicity_Latino', 'Ethnicity_caucasian', \n",
    "              'Country_region_East','Country_region_North', 'Country_region_South', 'Country_region_West',\n",
    "              'Hotel_Type_Airport Hotels', 'Hotel_Type_City Hotel','Hotel_Type_Resort', 'Booking_channel_Agent', \n",
    "              'Booking_channel_Direct','Booking_channel_Online','checkin_day_of_the_week','Booking_day_of_the_week']\n",
    "\n",
    "Features= Categorical+Continus\n",
    "X=Train_Data.loc[:,Categorical+Continus]\n",
    "y=Train_Data.loc[:,Label]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.05, random_state = 97)\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "#XGboost Classifier\n",
    "#model xgboost\n",
    "#use xgboost API now\n",
    "xgDMatrix = xgb.DMatrix(X_train, y_train) #create Dmatrix\n",
    "xgbDMatrixTest = xgb.DMatrix(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "This is number 0 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 1 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 2 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 3 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 4 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 5 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 6 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 7 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 8 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 9 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 10 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 11 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[2]\n",
      "This is number 12 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 13 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 14 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 15 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 16 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[2]\n",
      "This is number 17 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 18 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 19 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 20 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 21 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 22 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 23 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 24 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 25 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 26 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[0]\n",
      "This is number 27 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 28 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 29 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[2]\n",
      "This is number 30 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 31 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 32 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 33 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[0]\n",
      "This is number 34 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 35 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 36 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 37 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 38 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[2]\n",
      "This is number 39 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 40 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[2]\n",
      "This is number 41 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[0]\n",
      "This is number 42 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 43 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 44 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 45 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[1]\n",
      "This is number 46 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 47 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 48 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 49 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 50 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[6]\n",
      "This is number 51 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 52 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[3]\n",
      "This is number 53 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[4]\n",
      "This is number 54 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 55 generation\n",
      "Best F1 score in the this iteration = 0.8536363636363635\n",
      "[5]\n",
      "This is number 56 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[4]\n",
      "This is number 57 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 58 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 59 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 60 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n",
      "This is number 61 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[5]\n",
      "This is number 62 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[5]\n",
      "This is number 63 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 64 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[2]\n",
      "This is number 65 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n",
      "This is number 66 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 67 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[4]\n",
      "This is number 68 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 69 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 70 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 71 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n",
      "This is number 72 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[4]\n",
      "This is number 73 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 74 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[5]\n",
      "This is number 75 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 76 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[2]\n",
      "This is number 77 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 78 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n",
      "This is number 79 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[6]\n",
      "This is number 80 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[3]\n",
      "This is number 81 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[3]\n",
      "This is number 82 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[3]\n",
      "This is number 83 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[4]\n",
      "This is number 84 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[3]\n",
      "This is number 85 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[5]\n",
      "This is number 86 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n",
      "This is number 87 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[2]\n",
      "This is number 88 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 89 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 90 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[2]\n",
      "This is number 91 generation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[3]\n",
      "This is number 92 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[5]\n",
      "This is number 93 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[5]\n",
      "This is number 94 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 95 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 96 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n",
      "This is number 97 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[1]\n",
      "This is number 98 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[4]\n",
      "This is number 99 generation\n",
      "Best F1 score in the this iteration = 0.8536688311688312\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "numberOfParents = 8 #number of parents to start\n",
    "numberOfParentsMating = 4 #number of parents that will mate\n",
    "numberOfParameters = 7 #number of parameters that will be optimized\n",
    "numberOfGenerations = 100 #number of genration that will be created\n",
    "#define the population size\n",
    "populationSize = (numberOfParents, numberOfParameters)\n",
    "#initialize the population with randomly generated parameters\n",
    "population = initilialize_poplulation(numberOfParents)\n",
    "#define an array to store the fitness  hitory\n",
    "fitnessHistory = np.empty([numberOfGenerations+1, numberOfParents])\n",
    "#define an array to store the value of each parameter for each parent and generation\n",
    "populationHistory = np.empty([(numberOfGenerations+1)*numberOfParents, numberOfParameters])\n",
    "#insert the value of initial parameters in history\n",
    "populationHistory[0:numberOfParents, :] = population\n",
    "for generation in range(numberOfGenerations):\n",
    "    print(\"This is number %s generation\" % (generation))\n",
    "    \n",
    "    #train the dataset and obtain fitness\n",
    "    fitnessValue = train_population(population=population, dMatrixTrain=xgDMatrix, dMatrixtest=xgbDMatrixTest,\n",
    "                                    y_test=y_test,X=X,ys=y)\n",
    "    fitnessHistory[generation, :] = fitnessValue\n",
    "    \n",
    "    #best score in the current iteration\n",
    "    print('Best F1 score in the this iteration = {}'.format(np.max(fitnessHistory[generation, :])))\n",
    "#survival of the fittest - take the top parents, based on the fitness value and number of parents needed to be selected\n",
    "    parents = new_parents_selection(population=population, fitness=fitnessValue, numParents=numberOfParentsMating)\n",
    "    \n",
    "    #mate these parents to create children having parameters from these parents (we are using uniform crossover)\n",
    "    children = crossover_uniform(parents=parents, childrenSize=(populationSize[0] - parents.shape[0], numberOfParameters))\n",
    "    \n",
    "    #add mutation to create genetic diversity\n",
    "    children_mutated = mutation(children, numberOfParameters)\n",
    "    \n",
    "    '''\n",
    "    We will create new population, which will contain parents that where selected previously based on the\n",
    "    fitness score and rest of them  will be children\n",
    "    '''\n",
    "    population[0:parents.shape[0], :] = parents #fittest parents\n",
    "    population[parents.shape[0]:, :] = children_mutated #children\n",
    "    \n",
    "    populationHistory[(generation+1)*numberOfParents : (generation+1)*numberOfParents+ numberOfParents , :] = population #srore parent information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
